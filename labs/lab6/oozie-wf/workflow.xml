<workflow-app xmlns="uri:oozie:workflow:0.4" name="nycDrivers.ingestion">
  <global>
    <job-tracker>${jobTracker}</job-tracker>
    <name-node>${nameNode}</name-node>
  </global>

  <credentials>
    <credential name="hive-creds" type="hive2">
      <property>
        <name>hive2.server.principal</name>
        <value>${hivePrincipal}</value>
      </property>
      <property>
        <name>hive2.jdbc.url</name>
        <value>${jdbcUrl}</value>
      </property>
    </credential>
  </credentials>

  <start to="create-csv-table"/>

  <!-- 
    Some HDFS actions could be done before.
    For example, you can consider that the file is added to a transit zone in a folder with today's date as name.
    You need to move/copy it to the csv table folder.
  -->

  <action name="create-csv-table" cred="hive-creds">
    <hive2 xmlns="uri:oozie:hive2-action:0.2">
      <jdbc-url>${jdbcUrl}</jdbc-url>
      <script>scripts/create_drivers_ext.hql</script>
      <param>hiveUsername=${hiveUsername}</param>
    </hive2>
    <ok to="create-orc-table"/>
    <error to="kill-on-error"/>
  </action>

  <action name="create-orc-table" cred="hive-creds">
    <hive2 xmlns="uri:oozie:hive2-action:0.2">
      <jdbc-url>${jdbcUrl}</jdbc-url>
      <script>scripts/create_drivers_orc.hql</script>
      <param>hiveUsername=${hiveUsername}</param>
    </hive2>
    <ok to="insert-to-orc-from-csv"/>
    <error to="kill-on-error"/>
  </action>

  <action name="insert-to-orc-from-csv" cred="hive-creds">
    <hive2 xmlns="uri:oozie:hive2-action:0.2">
      <jdbc-url>${jdbcUrl}</jdbc-url>
      <script>scripts/insert_to_orc_from_csv.hql</script>
      <param>hiveUsername=${hiveUsername}</param>
    </hive2>
    <ok to="end"/>
    <error to="kill-on-error"/>
  </action>

  <kill name="kill-on-error">
    <message>Job failed</message>
  </kill>

  <end name="end" />
</workflow-app>
